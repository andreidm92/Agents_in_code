{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andreidm92/Agents_in_code/blob/main/practice/Lesson_6_salesbot_final_with_langgraph.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddzqQrP5-l9z"
      },
      "source": [
        "# Day 6 ‚Äî Financial Analyst: Sales Prospecting Assistant (Tech-Focused)\n",
        "\n",
        "**–¶–µ–ª—å:** –ü–æ—Å—Ç—Ä–æ–∏—Ç—å RAG-–±–æ—Ç–∞ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å PDF-–ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏—è–º–∏ –∏ –ø–∏—Å—å–º–∞–º–∏ –ø–æ –ø—Ä–æ–¥–∞–∂–∞–º.\n",
        "\n",
        "## üîç –ß—Ç–æ –±—É–¥–µ—Ç –≤ –Ω–æ—É—Ç–±—É–∫–µ\n",
        "- –ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã PDF-—Ñ–∞–π–ª–æ–≤ –ø–æ –ø—Ä–æ–¥–∞–∂–∞–º\n",
        "- –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Ä–∞–∑–±–∏–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ (`RecursiveTextSplitter`) –∏ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞\n",
        "- –ó–∞–ø—Ä–æ—Å—ã –∫ –±–æ—Ç—É –∏ –æ—Ü–µ–Ω–∫–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –æ—Ç–≤–µ—Ç–æ–≤\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQxruogu-l92"
      },
      "source": [
        "## üìÅ –¢–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö –≤ –ø—Ä–æ–¥–∞–∂–∞—Ö: –∑–∞—á–µ–º —ç—Ç–æ –≤–∞–∂–Ω–æ –¥–ª—è RAG\n",
        "- **–ü—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–∏** —Å–æ–¥–µ—Ä–∂–∞—Ç –±–ª–æ–∫–∏: –ø—Ä–æ–±–ª–µ–º–∞, —Ä–µ—à–µ–Ω–∏–µ, –≤—ã–≥–æ–¥—ã, –ø—Ä–∏–∑—ã–≤ –∫ –¥–µ–π—Å—Ç–≤–∏—é (CTA)\n",
        "- **–ü–∏—Å—å–º–∞** —á–∞—Å—Ç–æ —Å–ª–µ–¥—É—é—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä–µ AIDA (attention ‚Üí interest ‚Üí desire ‚Üí action)\n",
        "- –ë–æ—Ç –¥–æ–ª–∂–µ–Ω –∏–∑–≤–ª–µ–∫–∞—Ç—å **—Ü–∏—Ç–∞—Ç—ã**, **–≤—ã–≥–æ–¥—ã**, **—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏** –ø–æ –Ω—É–∂–Ω–æ–º—É —Å–µ–≥–º–µ–Ω—Ç—É"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Yy4o05C-l93"
      },
      "source": [
        "## üîß –≠—Ç–∞–ø—ã –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è RAG-–±–æ—Ç–∞\n",
        "1. –ó–∞–≥—Ä—É–∑–∫–∞ PDF-—Ñ–∞–π–ª–æ–≤\n",
        "2. –†–∞–∑–±–∏–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ —á–∞–Ω–∫–∏\n",
        "3. –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞\n",
        "4. –û—Ç–≤–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å ‚Üí –ø—Ä–æ–≤–µ—Ä–∫–∞: ¬´—Å—Å—ã–ª–∞–µ—Ç—Å—è –ª–∏ –±–æ—Ç –Ω–∞ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã?¬ª"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama-index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DW6C0UgkBzng",
        "outputId": "8cb7e2b1-d98e-4d45-dec7-09870c1f090c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-index\n",
            "  Downloading llama_index-0.12.37-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting llama-index-agent-openai<0.5,>=0.4.0 (from llama-index)\n",
            "  Downloading llama_index_agent_openai-0.4.8-py3-none-any.whl.metadata (438 bytes)\n",
            "Collecting llama-index-cli<0.5,>=0.4.1 (from llama-index)\n",
            "  Downloading llama_index_cli-0.4.1-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting llama-index-core<0.13,>=0.12.36 (from llama-index)\n",
            "  Downloading llama_index_core-0.12.37-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting llama-index-embeddings-openai<0.4,>=0.3.0 (from llama-index)\n",
            "  Downloading llama_index_embeddings_openai-0.3.1-py3-none-any.whl.metadata (684 bytes)\n",
            "Collecting llama-index-indices-managed-llama-cloud>=0.4.0 (from llama-index)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.6.11-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting llama-index-llms-openai<0.4,>=0.3.0 (from llama-index)\n",
            "  Downloading llama_index_llms_openai-0.3.42-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting llama-index-multi-modal-llms-openai<0.5,>=0.4.0 (from llama-index)\n",
            "  Downloading llama_index_multi_modal_llms_openai-0.4.3-py3-none-any.whl.metadata (726 bytes)\n",
            "Collecting llama-index-program-openai<0.4,>=0.3.0 (from llama-index)\n",
            "  Downloading llama_index_program_openai-0.3.1-py3-none-any.whl.metadata (764 bytes)\n",
            "Collecting llama-index-question-gen-openai<0.4,>=0.3.0 (from llama-index)\n",
            "  Downloading llama_index_question_gen_openai-0.3.0-py3-none-any.whl.metadata (783 bytes)\n",
            "Collecting llama-index-readers-file<0.5,>=0.4.0 (from llama-index)\n",
            "  Downloading llama_index_readers_file-0.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting llama-index-readers-llama-parse>=0.4.0 (from llama-index)\n",
            "  Downloading llama_index_readers_llama_parse-0.4.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.11/dist-packages (from llama-index) (3.9.1)\n",
            "Requirement already satisfied: openai>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-agent-openai<0.5,>=0.4.0->llama-index) (1.78.1)\n",
            "Requirement already satisfied: aiohttp<4,>=3.8.6 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.36->llama-index) (3.11.15)\n",
            "Collecting aiosqlite (from llama-index-core<0.13,>=0.12.36->llama-index)\n",
            "  Downloading aiosqlite-0.21.0-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting banks<3,>=2.0.0 (from llama-index-core<0.13,>=0.12.36->llama-index)\n",
            "  Downloading banks-2.1.2-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting dataclasses-json (from llama-index-core<0.13,>=0.12.36->llama-index)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting deprecated>=1.2.9.3 (from llama-index-core<0.13,>=0.12.36->llama-index)\n",
            "  Downloading Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting dirtyjson<2,>=1.0.8 (from llama-index-core<0.13,>=0.12.36->llama-index)\n",
            "  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting filetype<2,>=1.2.0 (from llama-index-core<0.13,>=0.12.36->llama-index)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.36->llama-index) (2025.3.2)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.36->llama-index) (0.28.1)\n",
            "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.36->llama-index) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.36->llama-index) (3.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.36->llama-index) (2.0.2)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.36->llama-index) (11.2.1)\n",
            "Requirement already satisfied: pydantic>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.36->llama-index) (2.11.4)\n",
            "Requirement already satisfied: pyyaml>=6.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.36->llama-index) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.36->llama-index) (2.32.3)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.49 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13,>=0.12.36->llama-index) (2.0.40)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.36->llama-index) (9.1.2)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.36->llama-index) (0.9.0)\n",
            "Requirement already satisfied: tqdm<5,>=4.66.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.36->llama-index) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.36->llama-index) (4.13.2)\n",
            "Collecting typing-inspect>=0.8.0 (from llama-index-core<0.13,>=0.12.36->llama-index)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.36->llama-index) (1.17.2)\n",
            "Collecting llama-cloud<0.2.0,>=0.1.13 (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud-0.1.22-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5,>=0.4.0->llama-index) (4.13.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5,>=0.4.0->llama-index) (2.2.2)\n",
            "Collecting pypdf<6.0.0,>=5.1.0 (from llama-index-readers-file<0.5,>=0.4.0->llama-index)\n",
            "  Downloading pypdf-5.5.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.5,>=0.4.0->llama-index)\n",
            "  Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.23-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index) (8.2.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index) (1.5.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index) (2024.11.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.36->llama-index) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.36->llama-index) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.36->llama-index) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.36->llama-index) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.36->llama-index) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.36->llama-index) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.36->llama-index) (1.20.0)\n",
            "Collecting griffe (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.36->llama-index)\n",
            "  Downloading griffe-1.7.3-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.36->llama-index) (3.1.6)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.36->llama-index) (4.3.8)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.5,>=0.4.0->llama-index) (2.7)\n",
            "Requirement already satisfied: certifi>=2024.7.4 in /usr/local/lib/python3.11/dist-packages (from llama-cloud<0.2.0,>=0.1.13->llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (2025.4.26)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13,>=0.12.36->llama-index) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13,>=0.12.36->llama-index) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13,>=0.12.36->llama-index) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.13,>=0.12.36->llama-index) (0.16.0)\n",
            "Collecting llama-cloud-services>=0.6.23 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.23-py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index) (1.3.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.36->llama-index) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.36->llama-index) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.36->llama-index) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.13,>=0.12.36->llama-index) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.13,>=0.12.36->llama-index) (2.4.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13,>=0.12.36->llama-index) (3.2.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core<0.13,>=0.12.36->llama-index)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core<0.13,>=0.12.36->llama-index)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->llama-index-readers-file<0.5,>=0.4.0->llama-index) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->llama-index-readers-file<0.5,>=0.4.0->llama-index) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->llama-index-readers-file<0.5,>=0.4.0->llama-index) (2025.2)\n",
            "Collecting python-dotenv<2.0.0,>=1.0.1 (from llama-cloud-services>=0.6.23->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.11/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13,>=0.12.36->llama-index) (24.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-readers-file<0.5,>=0.4.0->llama-index) (1.17.0)\n",
            "Collecting colorama>=0.4 (from griffe->banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.36->llama-index)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.36->llama-index) (3.0.2)\n",
            "Downloading llama_index-0.12.37-py3-none-any.whl (7.1 kB)\n",
            "Downloading llama_index_agent_openai-0.4.8-py3-none-any.whl (14 kB)\n",
            "Downloading llama_index_cli-0.4.1-py3-none-any.whl (28 kB)\n",
            "Downloading llama_index_core-0.12.37-py3-none-any.whl (7.7 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_embeddings_openai-0.3.1-py3-none-any.whl (6.2 kB)\n",
            "Downloading llama_index_indices_managed_llama_cloud-0.6.11-py3-none-any.whl (14 kB)\n",
            "Downloading llama_index_llms_openai-0.3.42-py3-none-any.whl (23 kB)\n",
            "Downloading llama_index_multi_modal_llms_openai-0.4.3-py3-none-any.whl (5.9 kB)\n",
            "Downloading llama_index_program_openai-0.3.1-py3-none-any.whl (5.3 kB)\n",
            "Downloading llama_index_question_gen_openai-0.3.0-py3-none-any.whl (2.9 kB)\n",
            "Downloading llama_index_readers_file-0.4.7-py3-none-any.whl (40 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m40.8/40.8 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_readers_llama_parse-0.4.0-py3-none-any.whl (2.5 kB)\n",
            "Downloading banks-2.1.2-py3-none-any.whl (28 kB)\n",
            "Downloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
            "Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
            "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading llama_cloud-0.1.22-py3-none-any.whl (265 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m265.9/265.9 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_parse-0.6.23-py3-none-any.whl (4.9 kB)\n",
            "Downloading pypdf-5.5.0-py3-none-any.whl (303 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m303.4/303.4 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading aiosqlite-0.21.0-py3-none-any.whl (15 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading llama_cloud_services-0.6.23-py3-none-any.whl (37 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Downloading griffe-1.7.3-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m129.3/129.3 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: striprtf, filetype, dirtyjson, python-dotenv, pypdf, mypy-extensions, marshmallow, deprecated, colorama, aiosqlite, typing-inspect, griffe, llama-cloud, dataclasses-json, banks, llama-index-core, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-cloud-services, llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, llama-index-readers-llama-parse, llama-index-program-openai, llama-index-question-gen-openai, llama-index\n",
            "Successfully installed aiosqlite-0.21.0 banks-2.1.2 colorama-0.4.6 dataclasses-json-0.6.7 deprecated-1.2.18 dirtyjson-1.0.8 filetype-1.2.0 griffe-1.7.3 llama-cloud-0.1.22 llama-cloud-services-0.6.23 llama-index-0.12.37 llama-index-agent-openai-0.4.8 llama-index-cli-0.4.1 llama-index-core-0.12.37 llama-index-embeddings-openai-0.3.1 llama-index-indices-managed-llama-cloud-0.6.11 llama-index-llms-openai-0.3.42 llama-index-multi-modal-llms-openai-0.4.3 llama-index-program-openai-0.3.1 llama-index-question-gen-openai-0.3.0 llama-index-readers-file-0.4.7 llama-index-readers-llama-parse-0.4.0 llama-parse-0.6.23 marshmallow-3.26.1 mypy-extensions-1.1.0 pypdf-5.5.0 python-dotenv-1.1.0 striprtf-0.0.26 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "D8DTRlJZ-l94"
      },
      "outputs": [],
      "source": [
        "# –ò–º–ø–æ—Ä—Ç—ã\n",
        "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex\n",
        "from llama_index.core.node_parser import SentenceSplitter\n",
        "from IPython.display import Markdown"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, getpass\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"–í—Å—Ç–∞–≤—å OpenAI API –∫–ª—é—á: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ZRf8jJfBYQ5",
        "outputId": "bd9307f6-5ca9-4240-8a0c-7c77ff6963ce"
      },
      "execution_count": 14,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "–í—Å—Ç–∞–≤—å OpenAI API –∫–ª—é—á: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "GXYhzm4W-l95"
      },
      "outputs": [],
      "source": [
        "# –ó–∞–≥—Ä—É–∑–∫–∞ PDF-–¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏–∑ –ø–∞–ø–∫–∏ 'data'\n",
        "docs = SimpleDirectoryReader(\"data\").load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üß∞ –ß—Ç–æ –¥–µ–ª–∞–µ—Ç SentenceSplitter:\n",
        "–†–∞–∑–±–∏–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç –Ω–∞ –ª–æ–≥–∏—á–µ—Å–∫–∏–µ —á–∞–Ω–∫–∏ (–±–ª–æ–∫–∏ –ø–æ ~500‚Äì1000 —Ç–æ–∫–µ–Ω–æ–≤)\n",
        "\n",
        "–î–µ–ª–∞–µ—Ç —ç—Ç–æ —Ä–µ–∫—É—Ä—Å–∏–≤–Ω–æ –ø–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ —Ç–µ–∫—Å—Ç–∞: —Å–Ω–∞—á–∞–ª–∞ –ø–æ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞–º ‚Üí –ø–æ—Ç–æ–º –ø–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º ‚Üí –ø–æ—Ç–æ–º –ø–æ —Å–ª–æ–≤–∞–º\n",
        "\n",
        "–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç overlap (–ø–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ), —á—Ç–æ–±—ã —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç –º–µ–∂–¥—É —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞–º–∏\n",
        "\n",
        "üéØ –ó–∞—á–µ–º —ç—Ç–æ –≤–∞–∂–Ω–æ:\n",
        "–ö–∞–∂–¥—ã–π —á–∞–Ω–∫ —Å—Ç–∞–Ω–æ–≤–∏—Ç—Å—è –æ—Ç–¥–µ–ª—å–Ω—ã–º Node –≤ LlamaIndex\n",
        "\n",
        "–í–µ–∫—Ç–æ—Ä–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ (embeddings) —Å–æ–∑–¥–∞—ë—Ç—Å—è –ø–æ –∫–∞–∂–¥–æ–º—É —á–∞–Ω–∫—É –æ—Ç–¥–µ–ª—å–Ω–æ\n",
        "\n",
        "–ü—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –±–æ—Ç –Ω–∞—Ö–æ–¥–∏—Ç –Ω–∞–∏–±–æ–ª–µ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —á–∞–Ω–∫–∏, –∞ –Ω–µ –≤–µ—Å—å –¥–æ–∫—É–º–µ–Ω—Ç\n",
        "\n",
        "üîπ –ï—Å–ª–∏ –Ω–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å–ø–ª–∏—Ç—Ç–µ—Ä ‚Äî –±—É–¥–µ—Ç –ª–∏–±–æ 1 –≥–∏–≥–∞–Ω—Ç—Å–∫–∏–π –≤–µ–∫—Ç–æ—Ä (–±–µ—Å–ø–æ–ª–µ–∑–Ω–æ), –ª–∏–±–æ –ø–æ—Ç–µ—Ä—è –ª–æ–≥–∏–∫–∏ –≤ –æ–±—Ä—ã–≤–∫–∞—Ö —Ç–µ–∫—Å—Ç–∞."
      ],
      "metadata": {
        "id": "09d9HeegCzUW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "LnS_9mqj-l95"
      },
      "outputs": [],
      "source": [
        "# ‚úÖ –†–∞–∑–±–∏–µ–Ω–∏–µ –Ω–∞ —á–∞–Ω–∫–∏ (Nodes)\n",
        "splitter = SentenceSplitter(chunk_size=512, chunk_overlap=64)\n",
        "nodes = splitter.get_nodes_from_documents(docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üì¶ Document\n",
        "\n",
        "–≠—Ç–æ –∏—Å—Ö–æ–¥–Ω—ã–π —Ñ–∞–π–ª –∏–ª–∏ —Ç–µ–∫—Å—Ç, –∫–æ—Ç–æ—Ä—ã–π —Ç—ã –∑–∞–≥—Ä—É–∂–∞–µ—à—å (PDF, DOCX, –ø–∏—Å—å–º–æ, —Å—Ç—Ä–∞–Ω–∏—Ü–∞ —Å–∞–π—Ç–∞ –∏ —Ç.–¥.)\n",
        "\n",
        "docs = SimpleDirectoryReader(\"data\").load_data()  # -> List[Document]\n",
        "üß† –í –Ω—ë–º –º–æ–∂–µ—Ç –±—ã—Ç—å:\n",
        "\n",
        "–æ–¥–∏–Ω –±–æ–ª—å—à–æ–π –±–ª–æ–∫ —Ç–µ–∫—Å—Ç–∞\n",
        "\n",
        "–º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ (–Ω–∞–∑–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞, –¥–∞—Ç–∞, –∫–∞—Ç–µ–≥–æ—Ä–∏—è –∏ —Ç.–ø.)\n",
        "\n",
        "–º–æ–∂–µ—Ç –≤–µ—Å–∏—Ç—å —Ç—ã—Å—è—á–∏ —Ç–æ–∫–µ–Ω–æ–≤\n",
        "\n",
        "üß© Node\n",
        "\n",
        "–≠—Ç–æ —Ñ—Ä–∞–≥–º–µ–Ω—Ç –¥–æ–∫—É–º–µ–Ω—Ç–∞ ‚Äî —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Ä–∞–∑–±–∏–µ–Ω–∏—è (splitter), –∫–æ—Ç–æ—Ä—ã–π —É–∂–µ –≥–æ—Ç–æ–≤ –∫ –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏ –∏ –ø–æ–∏—Å–∫—É.\n",
        "\n",
        "splitter = SentenceSplitter(chunk_size=512)\n",
        "nodes = splitter.get_nodes_from_documents(docs)  # -> List[TextNode]\n",
        "\n",
        "–ö–∞–∂–¥—ã–π Node:\n",
        "\n",
        "—Å–æ–¥–µ—Ä–∂–∏—Ç –Ω–µ–±–æ–ª—å—à–æ–π –∫—É—Å–æ–∫ —Ç–µ–∫—Å—Ç–∞ (—á–∞–Ω–∫)\n",
        "\n",
        "–∑–Ω–∞–µ—Ç, –∏–∑ –∫–∞–∫–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –æ–Ω –ø—Ä–∏—à—ë–ª\n",
        "\n",
        "–º–æ–∂–µ—Ç –∏–º–µ—Ç—å —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ, ID, –ø–æ–∑–∏—Ü–∏–∏ –∏ —Ç.–¥.\n",
        "\n",
        "üß† –ó–∞–ø–æ–º–Ω–∏ –ø—Ä–∞–≤–∏–ª–æ:\n",
        "\n",
        "Document ‚Üí —ç—Ç–æ \"—Å—ã—Ä–æ–π —Ç–µ–∫—Å—Ç\"\n",
        "\n",
        "Node ‚Üí —ç—Ç–æ \"–±–æ–µ–≤–æ–π —é–Ω–∏—Ç\" –¥–ª—è RAG\n",
        "\n",
        "–ù—É–∂–Ω–æ –ø–æ—Å—Ç—Ä–æ–∏—Ç—å –∏–Ω–¥–µ–∫—Å? ‚ûù –†–∞–±–æ—Ç–∞–π —Å Node."
      ],
      "metadata": {
        "id": "M8EjF9VhIscp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "NWKzFDJa-l95"
      },
      "outputs": [],
      "source": [
        "# ‚úÖ –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞ –∏ –¥–≤–∏–∂–∫–∞ –∑–∞–ø—Ä–æ—Å–æ–≤\n",
        "index = VectorStoreIndex(nodes)\n",
        "engine = index.as_query_engine()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "Cjk50aMe-l96",
        "outputId": "5692ac7d-40f2-45d3-8cc0-99bb9a94cf27"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "To quantify the issue, integrate compelling data points that validate the challenges faced by your prospects. This data not only substantiates the problem but also places it within a broader context, potentially underscoring the urgency of addressing the issue. By effectively communicating the significance of the problem and the potential repercussions of ignoring it, you can emphasize the need for a prompt and effective solution."
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# ‚úÖ –ü—Ä–∏–º–µ—Ä –∑–∞–ø—Ä–æ—Å–∞\n",
        "response = engine.query(\"How to quantify the Issue?\")\n",
        "Markdown(response.response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUBbz2km-l96"
      },
      "source": [
        "# –ü—Ä–∏–º–µ—Ä –∑–∞–ø—Ä–æ—Å–∞\n",
        "response = engine.query(\"–ß—Ç–æ –º–æ–∂–Ω–æ –ø—Ä–µ–¥–ª–æ–∂–∏—Ç—å –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–º—É –∫–ª–∏–µ–Ω—Ç—É –Ω–∞ —ç—Ç–∞–ø–µ –ø–µ—Ä–≤–æ–≥–æ –∫–æ–Ω—Ç–∞–∫—Ç–∞?\")\n",
        "Markdown(response.response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ObvLEdve-l96",
        "outputId": "d1fc0180-0e68-46ef-bb00-2db8f58847e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n",
            "hi [first name],\n",
            "i enjoyed our call today, and i hope you \n",
            "did too. here are the top value adds we \n",
            "went over: \n",
            "next steps: \n",
            "i‚Äôll [next step] so we can proceed to \n",
            "[shared goal].\n",
            "@[first name]: you mentioned \n",
            "needing to check [item], would it be \n",
            "possible to do so before [next step] \n",
            "so i can show \n",
            "---\n",
            "6\n",
            "6. multi-threading: looping the decision \n",
            "maker back in\n",
            "hi [first name],\n",
            "as an update, the team feedback has \n",
            "been very positive and we‚Äôve surfaced \n",
            "great use cases and potential results.\n",
            "we‚Äôre now preparing for an executive \n",
            "presentation, and we‚Äôd like to loop \n",
            "you in with you to showcase the \n",
            "in \n",
            "---\n",
            "7\n",
            "hi [first name],\n",
            "curious if i could put some time on \n",
            "your calendar ahead of our executive \n",
            "presentation on [date/time]?\n",
            "want to make sure we‚Äôre addressing all \n",
            "stakeholders in the call and surfacing \n",
            "any concerns the team has ahead of \n",
            "[next step for buyers].\n",
            "does [date/time] work?\n",
            "- [your name]\n",
            " \n",
            "---\n",
            "8\n",
            "hi [first name],\n",
            "totally get where you‚Äôre coming from.\n",
            "let‚Äôs hop on a quick call to align \n",
            "pricing with your budget plus answer \n",
            "any questions. i‚Äôm sure we can knock \n",
            "this out in 9 minutes tops.\n",
            "does [date/time] work?\n",
            "- [your name]\n",
            "8. negotiation\n",
            "why it works\n",
            "validate the objection \n",
            "do not apologi \n",
            "---\n",
            "comparative statistics that highlight the performance gap betweencompanies addressing similar challenges and those that aren't.\n",
            "industry benchmarks or averages that your prospect's issue deviatesfrom, illustrating the potential for improvement.\n",
            "trend data showing the evolution of this problem over t \n",
            "---\n",
            "slide four, serves as the grand unveiling of your product and company,intricately weaving them into the ongoing narrative.\n",
            "after showcasing a vision of a brighter future, now pivot to delineatehow your product's features are pivotal to realising this new reality.this can be accomplished through:\n",
            "con \n",
            "---\n"
          ]
        }
      ],
      "source": [
        "for node in nodes:\n",
        "    text = node.get_content().lower()\n",
        "    if any(kw.lower() in text for kw in [\n",
        "        \"comparative statistics\",\n",
        "        \"framing your product's capabilities\",\n",
        "        \"personalize your email\",\n",
        "        \"use a specific cta\"\n",
        "    ]):\n",
        "        print(text[:300], \"\\n---\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oeybY3wN-l96"
      },
      "source": [
        "## üß™ –ü—Ä–∞–∫—Ç–∏–∫–∞ 2: –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–æ–≤\n",
        "–ó–∞–ø—É—Å—Ç–∏–º —Å–µ—Ä–∏—é –∑–∞–ø—Ä–æ—Å–æ–≤ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏ –ø–æ—Å–º–æ—Ç—Ä–∏–º, –∫–∞–∫–∏–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –≤—ã–±–∏—Ä–∞–µ—Ç –±–æ—Ç."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TvTPNwhf-l97",
        "outputId": "fec3e3cf-65c7-4c43-da91-a5239cdfffcd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üß† –ó–∞–ø—Ä–æ—Å: How to close a deal?\n",
            "To close a deal effectively, it is crucial to only send your proposal after scheduling a call to walk through it with your buyers. This allows you to control the conversation, understand how your proposal is being received, and identify any potential hurdles. Additionally, take control of the next steps by gathering as much information as possible to address any concerns and ensure a smooth closing process. Proceed with caution during this crucial step to avoid jeopardizing the deal after putting in significant effort. \n",
            "\n",
            "üß† –ó–∞–ø—Ä–æ—Å: In what cases it is suitable to follow up email ?\n",
            "It is suitable to follow up with an email when you want to keep the message simple, provide useful insights even if the recipient doesn't buy from you, tell a story that resonates with the prospect's experience, and include a specific interest call-to-action to continue the conversation. \n",
            "\n",
            "üß† –ó–∞–ø—Ä–æ—Å: How to show benefits of your product to customer?\n",
            "Showcasing testimonials from satisfied customers who have experienced the benefits firsthand, presenting compelling statistics that underscore the effectiveness and efficiency of your product, and offering a comparative analysis of the market to highlight how your product differentiates itself from competitors are effective ways to demonstrate the benefits of your product to customers. Additionally, illustrating tangible benefits through detailed case studies and testimonials that showcase real-world applications and specific instances where your product significantly improved efficiency, profitability, or customer satisfaction can offer a compelling narrative of transformation and success. \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# TODO: –ù–µ—Å–∫–æ–ª—å–∫–æ –∑–∞–ø—Ä–æ—Å–æ–≤\n",
        "queries = [\n",
        "    \"How to close a deal?\",\n",
        "    \"In what cases it is suitable to follow up email ?\",\n",
        "    \"How to show benefits of your product to customer?\"\n",
        "]\n",
        "for q in queries:\n",
        "    print(f\"üß† –ó–∞–ø—Ä–æ—Å: {q}\")\n",
        "    print(engine.query(q).response, \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üß† –ó–∞—á–µ–º —ç—Ç–æ –Ω—É–∂–Ω–æ:\n",
        "\n",
        "–¢—ã —Å—Ç—Ä–æ–∏—à—å –±–æ—Ç–∞ –¥–ª—è –ø—Ä–æ–¥–∞–∂, –∏ —Ö–æ—á–µ—à—å:\n",
        "\n",
        "–∞–≤—Ç–æ–º–∞—Ç–æ–º –Ω–∞—Ö–æ–¥–∏—Ç—å –≤ –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏—è—Ö –∏ –ø–∏—Å—å–º–∞—Ö —Ñ—Ä–∞–∑—ã –æ –≤—ã–≥–æ–¥–∞—Ö\n",
        "\n",
        "–ø–µ—Ä–µ–¥–∞–≤–∞—Ç—å –∏—Ö –∫–æ–º–∞–Ω–¥–µ ‚Üí –Ω–∞–ø—Ä–∏–º–µ—Ä, –≤ –≤–∏–¥–µ —Ç–∞–±–ª–∏—Ü—ã –¥–ª—è CRM –∏–ª–∏ –º–∞—Ä–∫–µ—Ç–æ–ª–æ–≥–∞\n",
        "\n",
        "üìå –≠—Ç–æ –∏ –¥–µ–ª–∞–µ—Ç —ç—Ç–æ—Ç —ç–∫—Å–ø–æ—Ä—Ç: –≤—ã–¥–µ–ª—è–µ—Ç ‚Äú–≤—ã–≥–æ–¥—ã‚Äù ‚Üí —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤ —Ç–∞–±–ª–∏—Ü—É."
      ],
      "metadata": {
        "id": "MRJTvEt2U-GO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "tnsFQiDN-l97"
      },
      "outputs": [],
      "source": [
        "# TODO: –≠–∫—Å–ø–æ—Ä—Ç –≤ CSV\n",
        "import pandas as pd\n",
        "\n",
        "relevant = [\n",
        "    node.get_content()\n",
        "    for node in nodes\n",
        "    if \"–≤—ã–≥–æ–¥–∞\" in node.get_content().lower()\n",
        "]\n",
        "\n",
        "df = pd.DataFrame(relevant, columns=[\"Fragment\"])\n",
        "df.to_csv(\"extracted_sales_benefits.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STRr799D-l97"
      },
      "source": [
        "# üîÅ Part 2: LangGraph Loop –¥–ª—è —É—Ç–æ—á–Ω–µ–Ω–∏—è –∑–∞–ø—Ä–æ—Å–∞\n",
        "\n",
        "**–¶–µ–ª—å:** –µ—Å–ª–∏ –æ—Ç–≤–µ—Ç –∫–æ—Ä–æ—Ç–∫–∏–π –∏–ª–∏ –Ω–µ—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π, –ø–æ–≤—Ç–æ—Ä–Ω–æ –∑–∞–¥–∞—Ç—å –≤–æ–ø—Ä–æ—Å ‚Äî —É—Ç–æ—á–Ω—ë–Ω–Ω–æ.\n",
        "–ò—Å–ø–æ–ª—å–∑—É–µ–º LangGraph –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –ø—Ä–æ—Å—Ç–æ–≥–æ —Ü–∏–∫–ª–∞ –Ω–∞ 2 —É–∑–ª–∞:\n",
        "- `query_node`: –¥–µ–ª–∞–µ—Ç –∑–∞–ø—Ä–æ—Å\n",
        "- `refine_node`: –ø—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–ª–∏–Ω—É ‚Üí –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä—É–µ—Ç"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langgraph"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nX8L4nkZYa7e",
        "outputId": "7d13d438-a8a5-4b97-d7ed-44ecfd3bfd9f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langgraph\n",
            "  Downloading langgraph-0.4.5-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: langchain-core>=0.1 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.3.59)\n",
            "Collecting langgraph-checkpoint<3.0.0,>=2.0.26 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-2.0.26-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting langgraph-prebuilt>=0.1.8 (from langgraph)\n",
            "  Downloading langgraph_prebuilt-0.1.8-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting langgraph-sdk>=0.1.42 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.1.69-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langgraph) (2.11.4)\n",
            "Requirement already satisfied: xxhash<4.0.0,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from langgraph) (3.5.0)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (0.3.42)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (4.13.2)\n",
            "Collecting ormsgpack<2.0.0,>=1.8.0 (from langgraph-checkpoint<3.0.0,>=2.0.26->langgraph)\n",
            "  Downloading ormsgpack-1.9.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk>=0.1.42->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk>=0.1.42->langgraph) (3.10.18)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (0.4.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.1->langgraph) (3.0.0)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core>=0.1->langgraph) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core>=0.1->langgraph) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core>=0.1->langgraph) (0.23.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core>=0.1->langgraph) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core>=0.1->langgraph) (2.4.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (1.3.1)\n",
            "Downloading langgraph-0.4.5-py3-none-any.whl (155 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m155.3/155.3 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-2.0.26-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m44.2/44.2 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_prebuilt-0.1.8-py3-none-any.whl (25 kB)\n",
            "Downloading langgraph_sdk-0.1.69-py3-none-any.whl (48 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m48.9/48.9 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ormsgpack-1.9.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (223 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m223.6/223.6 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ormsgpack, langgraph-sdk, langgraph-checkpoint, langgraph-prebuilt, langgraph\n",
            "Successfully installed langgraph-0.4.5 langgraph-checkpoint-2.0.26 langgraph-prebuilt-0.1.8 langgraph-sdk-0.1.69 ormsgpack-1.9.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "L6-1TS5U-l97"
      },
      "outputs": [],
      "source": [
        "from langgraph.graph import StateGraph\n",
        "from typing import TypedDict\n",
        "from langchain.schema import BaseMessage\n",
        "\n",
        "# –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è\n",
        "class State(TypedDict):\n",
        "    question: str\n",
        "    history: list[str]\n",
        "    last_answer: str\n",
        "\n",
        "# –£–∑–µ–ª 1 ‚Äî –¥–µ–ª–∞–µ—Ç –∑–∞–ø—Ä–æ—Å\n",
        "def query_node(state: State) -> State:\n",
        "    answer = engine.query(state[\"question\"]).response.strip()\n",
        "    state[\"history\"].append(answer)\n",
        "    state[\"last_answer\"] = answer\n",
        "    return state\n",
        "\n",
        "# –£–∑–µ–ª 2 ‚Äî –ø—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–ª–∏–Ω—É –æ—Ç–≤–µ—Ç–∞\n",
        "def refine_node(state: State) -> str:\n",
        "    if len(state[\"last_answer\"].split()) < 20:\n",
        "        state[\"question\"] = f\"–ü–æ–ø—Ä–æ–±—É–π —Ç–æ—á–Ω–µ–µ: {state['question']}\"\n",
        "        return \"query\"\n",
        "    return \"end\"\n",
        "\n",
        "# –î–æ–±–∞–≤–∏–º —Ñ–∏–∫—Ç–∏–≤–Ω—ã–π end-—É–∑–µ–ª\n",
        "def end_node(state: State) -> State:\n",
        "    return state  # –ø—Ä–æ—Å—Ç–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ñ–∏–Ω–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üìå –í LangGraph —Ç—ã –¥–æ–ª–∂–µ–Ω –¥–æ–±–∞–≤–∏—Ç—å –≤—Å–µ —É–∑–ª—ã, –¥–∞–∂–µ \"end\". –û–Ω –Ω–µ —Å–æ–∑–¥–∞—ë—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏.\n",
        "\n"
      ],
      "metadata": {
        "id": "mRcSKoVDafK6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggTlmS5U-l98",
        "outputId": "0597f92d-838e-4e89-d6cd-032699be1ad7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîÅ –ò—Å—Ç–æ—Ä–∏—è –∏—Ç–µ—Ä–∞—Ü–∏–π:\n",
            "\n",
            "1) Offer testimonials from satisfied customers, present compelling statistics showcasing product effectiveness, provide a comparative analysis of the market to highlight product differentiation, include case studies or success stories illustrating impact on similar businesses, discuss industry benchmarks, and demonstrate how the product helps clients exceed standards. Additionally, highlight specific, quantifiable improvements that the client can expect upon integrating the product, offer predictions on improvement degrees for key performance indicators, and provide a realistic timeline for when these benefits are likely to manifest.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# –°–±–æ—Ä–∫–∞ –≥—Ä–∞—Ñ–∞\n",
        "graph = StateGraph(State)\n",
        "graph.add_node(\"query\", query_node)\n",
        "graph.add_node(\"end\", end_node)  # –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ!\n",
        "graph.add_conditional_edges(\"query\", refine_node)\n",
        "graph.set_entry_point(\"query\")\n",
        "graph.set_finish_point(\"end\")\n",
        "app = graph.compile()\n",
        "\n",
        "# –ó–∞–ø—É—Å–∫\n",
        "initial_state = {\n",
        "    \"question\": \"–ß—Ç–æ –ø—Ä–µ–¥–ª–æ–∂–∏—Ç—å –∫–ª–∏–µ–Ω—Ç—É?\",\n",
        "    \"history\": [],\n",
        "    \"last_answer\": \"\"\n",
        "}\n",
        "\n",
        "final_state = app.invoke(initial_state)\n",
        "\n",
        "# –í—ã–≤–æ–¥\n",
        "print(\"üîÅ –ò—Å—Ç–æ—Ä–∏—è –∏—Ç–µ—Ä–∞—Ü–∏–π:\\n\")\n",
        "for i, step in enumerate(final_state[\"history\"], 1):\n",
        "    print(f\"{i}) {step}\\n\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üß± class State(TypedDict)\n",
        "–≠—Ç–æ —Ñ–æ—Ä–º–∞—Ç —Å–æ—Å—Ç–æ—è–Ω–∏—è, –∫–æ—Ç–æ—Ä–æ–µ ¬´—Ç–µ—á—ë—Ç¬ª –ø–æ –≥—Ä–∞—Ñ—É.\n",
        "\n",
        "class State(TypedDict):\n",
        "    question: str\n",
        "    history: list[str]\n",
        "question: —Ç–µ–∫—É—â–∏–π —Ç–µ–∫—Å—Ç –∑–∞–ø—Ä–æ—Å–∞\n",
        "\n",
        "history: —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –æ—Ç–≤–µ—Ç–æ–≤ –±–æ—Ç–∞\n",
        "\n",
        "last_answer: –ø–æ—Å–ª–µ–¥–Ω–∏–π –æ—Ç–≤–µ—Ç, —á—Ç–æ–±—ã –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –µ–≥–æ –¥–ª–∏–Ω—É\n",
        "\n",
        "üîÑ def query_node(...)\n",
        "–≠—Ç–æ—Ç —É–∑–µ–ª –¥–µ–ª–∞–µ—Ç –æ—Å–Ω–æ–≤–Ω–æ–π –∑–∞–ø—Ä–æ—Å:\n",
        "\n",
        "answer = engine.query(state[\"question\"]).response.strip()\n",
        "–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –æ—Ç–≤–µ—Ç –≤ history\n",
        "\n",
        "–û–±–Ω–æ–≤–ª—è–µ—Ç last_answer\n",
        "\n",
        "üîÅ def refine_node(...)\n",
        "–†–µ—à–∞–µ—Ç, –Ω—É–∂–Ω–æ –ª–∏ —É—Ç–æ—á–Ω–µ–Ω–∏–µ:\n",
        "\n",
        "\n",
        "if len(state[\"last_answer\"].split()) < 20:\n",
        "    state[\"question\"] = f\"–ü–æ–ø—Ä–æ–±—É–π —Ç–æ—á–Ω–µ–µ: {state['question']}\"\n",
        "    return \"query\"  # –¶–∏–∫–ª\n",
        "return \"end\"\n",
        "–ï—Å–ª–∏ –æ—Ç–≤–µ—Ç –∫–æ—Ä–æ—á–µ 20 —Å–ª–æ–≤ ‚Üí —Å—á–∏—Ç–∞–µ–º –µ–≥–æ —Å–ª–∞–±—ã–º ‚Üí –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä—É–µ–º –≤–æ–ø—Ä–æ—Å ‚Üí –≤–æ–∑–≤—Ä–∞—â–∞–µ–º—Å—è –≤ query\n",
        "\n",
        "–ò–Ω–∞—á–µ ‚Äî –∑–∞–≤–µ—Ä—à–∞–µ–º\n",
        "\n",
        "üéØ –†–µ–∑—É–ª—å—Ç–∞—Ç:\n",
        "–ï—Å–ª–∏ –±–æ—Ç –¥–∞—ë—Ç \"–ø—É—Å—Ç–æ–π\" –∏–ª–∏ –æ–±—â–∏–π –æ—Ç–≤–µ—Ç ‚Äî LangGraph –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —É—Ç–æ—á–Ω—è–µ—Ç –≤–æ–ø—Ä–æ—Å –∏ –ø–æ–≤—Ç–æ—Ä—è–µ—Ç.\n",
        "\n"
      ],
      "metadata": {
        "id": "w0CUEW2batTu"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yA0taDjXZhi4"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}