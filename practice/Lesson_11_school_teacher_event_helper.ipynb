{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andreidm92/Agents_in_code/blob/main/practice/Lesson_11_school_teacher_event_helper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5165286d",
      "metadata": {
        "id": "5165286d"
      },
      "source": [
        "\n",
        "# üéì Day 11 ‚Äî School Teacher: Event Agenda Helper\n",
        "\n",
        "## üìò –¢–µ–æ—Ä–∏—è\n",
        "\n",
        "---\n",
        "\n",
        "### üîπ YouTubeTranscriptLoader (LlamaIndex)\n",
        "`YouTubeTranscriptReader` ‚Äî –∑–∞–≥—Ä—É–∑—á–∏–∫ —Å—É–±—Ç–∏—Ç—Ä–æ–≤ —Å YouTube. –ü–æ–∑–≤–æ–ª—è–µ—Ç –∏–∑–≤–ª–µ–∫–∞—Ç—å —Ç–µ–∫—Å—Ç –∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –µ–≥–æ –≤ –∏–Ω–¥–µ–∫—Å–∞—Ö LlamaIndex.\n",
        "\n",
        "```python\n",
        "from llama_index.readers import YouTubeTranscriptReader\n",
        "\n",
        "reader = YouTubeTranscriptReader()\n",
        "documents = reader.load_data([\"https://www.youtube.com/watch?v=jNQXAC9IVRw\"])\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### üîπ Error Recovery (LangGraph)\n",
        "LangGraph –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –ø–æ—Å–ª–µ –æ—à–∏–±–æ–∫, —á—Ç–æ –∫—Ä–∏—Ç–∏—á–Ω–æ –ø—Ä–∏ —Å–±–æ—è—Ö API.\n",
        "\n",
        "```python\n",
        "def main_node(state):\n",
        "    try:\n",
        "        result = run_risky_llm_call(state)\n",
        "        return {\"result\": result}\n",
        "    except Exception as e:\n",
        "        return {\"error\": str(e), \"__error__\": True}\n",
        "\n",
        "graph.add_conditional_edges(\"main\", lambda state: \"error\" if \"__error__\" in state else \"success\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### üîπ Conditional Edges (LangGraph)\n",
        "–ü–æ–∑–≤–æ–ª—è—é—Ç —Å–æ–∑–¥–∞–≤–∞—Ç—å –≤–µ—Ç–≤–ª–µ–Ω–∏—è –≤ –≥—Ä–∞—Ñ–µ, –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Å–æ—Å—Ç–æ—è–Ω–∏—è –∞–≥–µ–Ω—Ç–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, —É—Å–ø–µ—à–Ω–æ/–æ—à–∏–±–∫–∞).\n",
        "\n",
        "```python\n",
        "graph.add_node(\"process\", process_fn)\n",
        "graph.add_node(\"handle_error\", error_fn)\n",
        "graph.set_entry_point(\"process\")\n",
        "\n",
        "def edge_decision(state):\n",
        "    return \"handle_error\" if state.get(\"error\") else \"next_step\"\n",
        "\n",
        "graph.add_conditional_edges(\"process\", edge_decision)\n",
        "```\n",
        "\n",
        "üìå –ü—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è –¥–ª—è:  \n",
        "- –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—à–∏–±–æ–∫  \n",
        "- –≤—ã–±–æ—Ä–∞ —Å—Ü–µ–Ω–∞—Ä–∏—è –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –≤–≤–æ–¥–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è  \n",
        "- –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏–∏ –ø–æ —Å—Ç–∞—Ç—É—Å—É –¥–∞–Ω–Ω—ã—Ö\n",
        "\n",
        "---\n",
        "\n",
        "## üß™ –ü—Ä–∞–∫—Ç–∏–∫–∞\n",
        "\n",
        "–°–æ–∑–¥–∞–π—Ç–µ –ø–æ–º–æ—â–Ω–∏–∫–∞ –ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—è, –∫–æ—Ç–æ—Ä—ã–π:\n",
        "1. –ü—Ä–∏–Ω–∏–º–∞–µ—Ç —Å—Å—ã–ª–∫—É –Ω–∞ YouTube.\n",
        "2. –ó–∞–≥—Ä—É–∂–∞–µ—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç.\n",
        "3. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø–æ–≤–µ—Å—Ç–∫—É –∑–∞–Ω—è—Ç–∏—è –∏ –∫—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ.\n",
        "4. –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç retry –ø—Ä–∏ –æ—à–∏–±–∫–µ.\n",
        "5. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç —É—Å–ª–æ–≤–Ω—ã–µ –ø–µ—Ä–µ—Ö–æ–¥—ã LangGraph –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—à–∏–±–æ–∫.\n",
        "\n",
        "---\n",
        "\n",
        "## ‚öôÔ∏è –£—Å—Ç–∞–Ω–æ–≤–∫–∞\n",
        "\n",
        "```python\n",
        "!pip install llama-index youtube-transcript-api openai\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## üì• –ó–∞–≥—Ä—É–∑–∫–∞ YouTube-—Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–∞\n",
        "\n",
        "```python\n",
        "from llama_index.readers import YouTubeTranscriptReader\n",
        "\n",
        "reader = YouTubeTranscriptReader()\n",
        "documents = reader.load_data([\"<–í–°–¢–ê–í–¨–¢–ï_–°–°–´–õ–ö–£_–ù–ê_YOUTUBE>\"])\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## üìö –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–æ–≤–µ—Å—Ç–∫–∏\n",
        "\n",
        "```python\n",
        "from llama_index.core import VectorStoreIndex\n",
        "\n",
        "index = VectorStoreIndex.from_documents(documents)\n",
        "response = index.as_query_engine().query(\"–°—Ñ–æ—Ä–º–∏—Ä—É–π –ø–æ–≤–µ—Å—Ç–∫—É –∑–∞–Ω—è—Ç–∏—è –∏ –∫—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ\")\n",
        "\n",
        "print(response)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## üö® –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫\n",
        "\n",
        "```python\n",
        "try:\n",
        "    response = index.as_query_engine().query(\"–°—Ñ–æ—Ä–º–∏—Ä—É–π –ø–æ–≤–µ—Å—Ç–∫—É –∑–∞–Ω—è—Ç–∏—è –∏ –∫—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ\")\n",
        "    print(response)\n",
        "except Exception as e:\n",
        "    print(\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏:\", e)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## üß© Conditional Edges: —à–∞–±–ª–æ–Ω LangGraph\n",
        "\n",
        "```python\n",
        "from langgraph.graph import StateGraph\n",
        "\n",
        "def process_node(state):\n",
        "    # –ü—Ä–∏–º–µ—Ä –≤—ã–∑–æ–≤–∞ LLM –∏–ª–∏ API\n",
        "    if \"fail\" in state.get(\"mode\", \"\"):\n",
        "        raise ValueError(\"–°–∏–º—É–ª–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞\")\n",
        "    return {\"result\": \"–£—Å–ø–µ—à–Ω–æ\"}\n",
        "\n",
        "def error_node(state):\n",
        "    return {\"error_handled\": True}\n",
        "\n",
        "graph = StateGraph()\n",
        "graph.add_node(\"process\", process_node)\n",
        "graph.add_node(\"handle_error\", error_node)\n",
        "graph.set_entry_point(\"process\")\n",
        "\n",
        "graph.add_conditional_edges(\"process\", lambda state: \"handle_error\" if \"error\" in state else \"success\")\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ‚öôÔ∏è –£—Å—Ç–∞–Ω–æ–≤–∫–∞"
      ],
      "metadata": {
        "id": "HibYvZPW_2Zg"
      },
      "id": "HibYvZPW_2Zg"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q llama-index youtube-transcript-api openai langgraph\n",
        "!pip install -q llama-index-readers-youtube-transcript\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tHmvL1R_ZNh",
        "outputId": "d0f37bf1-9084-4c8d-c1a7-64c6c6cedd22"
      },
      "id": "-tHmvL1R_ZNh",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m154.9/154.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m44.2/44.2 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m50.0/50.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m216.5/216.5 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, getpass\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"–í—Å—Ç–∞–≤—å OpenAI API –∫–ª—é—á: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3Sb9GVABSl6",
        "outputId": "d206feca-0e8f-4b3c-dd73-d6a4fe9f8226"
      },
      "id": "l3Sb9GVABSl6",
      "execution_count": 2,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "–í—Å—Ç–∞–≤—å OpenAI API –∫–ª—é—á: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üì• –ó–∞–≥—Ä—É–∑–∫–∞ YouTube-—Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–∞"
      ],
      "metadata": {
        "id": "j4PAzKqIAJ5X"
      },
      "id": "j4PAzKqIAJ5X"
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.readers.youtube_transcript import YoutubeTranscriptReader\n",
        "\n",
        "# Initialize the reader\n",
        "reader = YoutubeTranscriptReader()\n",
        "\n",
        "# Load data from the YouTube video\n",
        "documents = reader.load_data(ytlinks=[\"https://www.youtube.com/watch?v=J_0qvRt4LNk\"])\n"
      ],
      "metadata": {
        "id": "EfmLOHus_4jD"
      },
      "id": "EfmLOHus_4jD",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üìö –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–æ–≤–µ—Å—Ç–∫–∏"
      ],
      "metadata": {
        "id": "CdxQI6cXBouu"
      },
      "id": "CdxQI6cXBouu"
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import VectorStoreIndex\n",
        "\n",
        "index = VectorStoreIndex.from_documents(documents)\n",
        "response = index.as_query_engine().query(\"–û —á–µ–º —ç—Ç–æ—Ç –¥–æ–∫—É–º–µ–Ω—Ç\")\n",
        "\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmme32K9BqWS",
        "outputId": "3f694abf-8aea-4aed-c33b-91215c1abf57"
      },
      "id": "wmme32K9BqWS",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "–î–æ–∫—É–º–µ–Ω—Ç –æ —Ç–æ–º, –∫–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Lang chain –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –ø—Ä–æ–º–ø—Ç–æ–≤ –∏ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π —è–∑—ã–∫–∞ –¥–ª—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∑–∞–¥–∞—á, —Ç–∞–∫–∏—Ö –∫–∞–∫ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –Ω–∞–∑–≤–∞–Ω–∏–π —Ä–µ—Å—Ç–æ—Ä–∞–Ω–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏—Ö –æ–ø–∏—Å–∞–Ω–∏—è –∏ –Ω–∞—Ö–æ–∂–¥–µ–Ω–∏–µ –∞–Ω—Ç–æ–Ω–∏–º–æ–≤ –¥–ª—è –∑–∞–¥–∞–Ω–Ω—ã—Ö —Å–ª–æ–≤ —Å –ø–æ–º–æ—â—å—é –ø—Ä–∏–º–µ—Ä–æ–≤.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üö® –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫"
      ],
      "metadata": {
        "id": "LY3C3T9u5wQl"
      },
      "id": "LY3C3T9u5wQl"
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    response = index.as_query_engine().query(\"–î–ª—è —á–µ–≥–æ –Ω—É–∂–µ–Ω Lang chain\")\n",
        "    print(response)\n",
        "except Exception as e:\n",
        "    print(\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏:\", e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ct-xwQ_v51aS",
        "outputId": "39b01868-c2f0-49b1-82ef-0b980eddc2eb"
      },
      "id": "ct-xwQ_v51aS",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lang chain is needed to build fully featured apps that interact with the normal software stack, manage the use of large language models and prompts, integrate with traditional software stack components like APIs, tools, calculators, databases, and data sources, and handle prompt templates effectively.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üß© Conditional Edges: —à–∞–±–ª–æ–Ω LangGraph\n",
        "\n",
        "üß© Conditional Edges –≤ LangGraph ‚Äî —ç—Ç–æ –º–µ—Ö–∞–Ω–∏–∑–º —É—Å–ª–æ–≤–Ω—ã—Ö –ø–µ—Ä–µ—Ö–æ–¥–æ–≤ –º–µ–∂–¥—É —É–∑–ª–∞–º–∏ –≤ LangGraph (—Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –≥—Ä–∞—Ñ–æ–≤ —Å–æ—Å—Ç–æ—è–Ω–∏–π –¥–ª—è LLM-–∞–≥–µ–Ω—Ç–æ–≤).\n",
        "\n",
        "üìå –ß—Ç–æ —Ç–∞–∫–æ–µ Conditional Edge?\n",
        "–≠—Ç–æ –ø—Ä–∞–≤–∏–ª–æ, –∫–æ—Ç–æ—Ä–æ–µ –≥–æ–≤–æ—Ä–∏—Ç:\n",
        "\n",
        "\"–ü–æ—Å–ª–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —É–∑–ª–∞ X ‚Äî –ø–µ—Ä–µ–π–¥–∏ –∫ Y –∏–ª–∏ Z –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞.\"\n",
        "\n",
        "üîß –ü—Ä–∏–º–µ—Ä –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è:\n",
        "\n",
        "graph.add_conditional_edges(\"process\", lambda state: \"handle_error\" if \"error\" in state else \"next_step\")\n",
        "\n",
        "–ó–¥–µ—Å—å:\n",
        "\n",
        "process ‚Äî —Ç–µ–∫—É—â–∏–π —É–∑–µ–ª (Node),\n",
        "\n",
        "lambda state: ... ‚Äî —Ñ—É–Ω–∫—Ü–∏—è –≤—ã–±–æ—Ä–∞ —Å–ª–µ–¥—É—é—â–µ–≥–æ —à–∞–≥–∞,\n",
        "\n",
        "\"handle_error\" ‚Äî –µ—Å–ª–∏ –≤–æ–∑–Ω–∏–∫–ª–∞ –æ—à–∏–±–∫–∞,\n",
        "\n",
        "\"next_step\" ‚Äî –µ—Å–ª–∏ –≤—Å—ë –ø—Ä–æ—à–ª–æ —É—Å–ø–µ—à–Ω–æ.\n",
        "\n",
        "\n",
        "üéØ –ö–æ–≥–¥–∞ –∏ –∑–∞—á–µ–º —ç—Ç–æ –Ω—É–∂–Ω–æ\n",
        "–°—Ü–µ–Ω–∞—Ä–∏–π\t–ö–∞–∫ –ø–æ–º–æ–≥–∞–µ—Ç Conditional Edge\n",
        "‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫\t–ï—Å–ª–∏ state —Å–æ–¥–µ—Ä–∂–∏—Ç error, –ø–µ—Ä–µ–π—Ç–∏ –∫ —É–∑–ª—É —Å retry –∏–ª–∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º\n",
        "üîÑ –ü–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞\t–ï—Å–ª–∏ LLM –¥–∞–ª –Ω–∏–∑–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç ‚Äî –ø–µ—Ä–µ–ø–∏—Å–∞—Ç—å –∏ –∑–∞–ø—É—Å—Ç–∏—Ç—å —Å–Ω–æ–≤–∞\n",
        "üîÄ –í–µ—Ç–≤–ª–µ–Ω–∏–µ –ª–æ–≥–∏–∫–∏\t–ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –≤—ã–±—Ä–∞–ª \"A\" ‚Äî –∏–¥—ë–º –≤ —É–∑–µ–ª A, –µ—Å–ª–∏ \"B\" ‚Äî –≤ —É–∑–µ–ª B\n",
        "üß† LLM –≤—ã–±–∏—Ä–∞–µ—Ç –ø—É—Ç—å\t–ù–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–æ–º–ø—Ç–∞ –∞–≥–µ–Ω—Ç —Ä–µ—à–∞–µ—Ç, –∫–∞–∫–æ–π tool –∏–ª–∏ –ø–æ–¥–≥—Ä–∞—Ñ –≤—ã–∑—ã–≤–∞—Ç—å\n",
        "\n",
        "üí° –ö–∞–∫ —É—Å—Ç—Ä–æ–µ–Ω–æ\n",
        "–ö–∞–∂–¥—ã–π —É–∑–µ–ª –≤ LangGraph –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç state: dict.\n",
        "\n",
        "–§—É–Ω–∫—Ü–∏—è –ø–µ—Ä–µ—Ö–æ–¥–∞ (lambda) —Å–º–æ—Ç—Ä–∏—Ç –≤ —ç—Ç–æ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç, –∫–∞–∫–æ–π —É–∑–µ–ª –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞—Ç—å –¥–∞–ª—å—à–µ.\n",
        "\n",
        "–≠—Ç–æ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞ if/else –≤ –æ–±—ã—á–Ω–æ–º –∫–æ–¥–µ ‚Äî –Ω–æ –≤–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–µ–º–∞—è –∏ —É—Å—Ç–æ–π—á–∏–≤–æ –∏—Å–ø–æ–ª–Ω—è–µ–º–∞—è –∫–∞–∫ –≥—Ä–∞—Ñ."
      ],
      "metadata": {
        "id": "dgRQTZjD6GG5"
      },
      "id": "dgRQTZjD6GG5"
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import StateGraph\n",
        "from typing import TypedDict, Optional\n",
        "\n",
        "class State(TypedDict, total=False):\n",
        "    mode: Optional[str]\n",
        "    result: Optional[str]\n",
        "    error: Optional[str]\n",
        "    msg: Optional[str]\n",
        "    completed: Optional[bool]\n",
        "    handled: Optional[bool]\n",
        "\n",
        "def process_node(state):\n",
        "    if \"fail\" in state.get(\"mode\", \"\"):\n",
        "        return {\"error\": \"–û—à–∏–±–∫–∞ –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ\"}\n",
        "    return {\"result\": \"–£—Å–ø–µ—à–Ω–æ\"}\n",
        "\n",
        "def error_node(state):\n",
        "    return {\"handled\": True, \"msg\": \"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞\"}\n",
        "\n",
        "def success_node(state):\n",
        "    return {\"completed\": True, \"msg\": \"–ü—Ä–æ—Ü–µ—Å—Å —É—Å–ø–µ—à–µ–Ω\"}\n",
        "\n",
        "graph = StateGraph(State)\n",
        "graph.add_node(\"process\", process_node)\n",
        "graph.add_node(\"handle_error\", error_node)\n",
        "graph.add_node(\"success\", success_node)\n",
        "graph.set_entry_point(\"process\")\n",
        "\n",
        "graph.add_conditional_edges(\"process\", lambda state: \"handle_error\" if \"error\" in state else \"success\")\n",
        "\n",
        "app = graph.compile()\n",
        "print(app.invoke({\"mode\": \"normal\"}))\n",
        "print(app.invoke({\"mode\": \"fail\"}))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPIIGoL40Y6C",
        "outputId": "d0e6d50b-ba6c-4a51-b454-b5537ba58edc"
      },
      "id": "oPIIGoL40Y6C",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'mode': 'normal', 'result': '–£—Å–ø–µ—à–Ω–æ', 'msg': '–ü—Ä–æ—Ü–µ—Å—Å —É—Å–ø–µ—à–µ–Ω', 'completed': True}\n",
            "{'mode': 'fail', 'error': '–û—à–∏–±–∫–∞ –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ', 'msg': '–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞', 'handled': True}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üîß Error Recovery –≤ LangGraph ‚Äî –ø–æ–¥—Ä–æ–±–Ω—ã–π —Ä–∞–∑–±–æ—Ä\n",
        "Error Recovery ‚Äî —ç—Ç–æ –º–µ—Ö–∞–Ω–∏–∑–º —É—Å—Ç–æ–π—á–∏–≤–æ–≥–æ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –∏—Å–ø–æ–ª–Ω–µ–Ω–∏—è –≥—Ä–∞—Ñ–∞, –µ—Å–ª–∏ –≤ –∫–∞–∫–æ–º-–ª–∏–±–æ —É–∑–ª–µ (node) –≤–æ–∑–Ω–∏–∫–∞–µ—Ç –æ—à–∏–±–∫–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, —Å–±–æ–π –≤—ã–∑–æ–≤–∞ LLM, –ø–∞–¥–µ–Ω–∏–µ API, TimeoutError).\n",
        "\n",
        "‚ùó –ü–æ—á–µ–º—É —ç—Ç–æ –≤–∞–∂–Ω–æ\n",
        "–ü—Ä–∏ —Ä–∞–±–æ—Ç–µ —Å LLM-–∞–≥–µ–Ω—Ç–∞–º–∏ –∏ API —á–∞—Å—Ç–æ –≤–æ–∑–º–æ–∂–Ω—ã:\n",
        "\n",
        "–Ω–µ—Å—Ç–∞–±–∏–ª—å–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã –º–æ–¥–µ–ª–∏,\n",
        "\n",
        "—Ç–∞–π–º–∞—É—Ç—ã,\n",
        "\n",
        "–æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –ø–æ–ª—è –≤ JSON,\n",
        "\n",
        "–ø—Ä–µ–≤—ã—à–µ–Ω–∏–µ –ª–∏–º–∏—Ç–æ–≤.\n",
        "\n",
        "–ë–µ–∑ Error Recovery –≤–µ—Å—å pipeline \"–ø–∞–¥–∞–µ—Ç\". LangGraph –ø–æ–∑–≤–æ–ª—è–µ—Ç –ø–µ—Ä–µ—Ö–≤–∞—Ç—ã–≤–∞—Ç—å –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å —Å–±–æ–∏, —á—Ç–æ–±—ã –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ.\n",
        "\n",
        "üß© –ö–∞–∫ —Ä–µ–∞–ª–∏–∑—É–µ—Ç—Å—è Error Recovery –≤ LangGraph\n",
        "–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è Conditional Edge + try/except –≤ —É–∑–ª–µ.\n",
        "\n",
        "–®–∞–≥–∏:\n",
        "–í —É–∑–ª–µ (node) –æ–±–æ—Ä–∞—á–∏–≤–∞–µ–º –≤—ã–∑–æ–≤ risky-–æ–ø–µ—Ä–∞—Ü–∏–∏ –≤ try/except.\n",
        "\n",
        "–ï—Å–ª–∏ –∏—Å–∫–ª—é—á–µ–Ω–∏–µ ‚Äî –¥–æ–±–∞–≤–ª—è–µ–º –≤ state —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π –∫–ª—é—á (\"__error__\" –∏–ª–∏ \"error\").\n",
        "\n",
        "–ò—Å–ø–æ–ª—å–∑—É–µ–º add_conditional_edges, —á—Ç–æ–±—ã –Ω–∞ —ç—Ç–æ–º –æ—Å–Ω–æ–≤–∞–Ω–∏–∏ –ø–µ—Ä–µ–π—Ç–∏ –≤ handle_error.\n",
        "\n"
      ],
      "metadata": {
        "id": "kSybhWhWDMsI"
      },
      "id": "kSybhWhWDMsI"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qAf_HRsO8a-U"
      },
      "id": "qAf_HRsO8a-U",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}