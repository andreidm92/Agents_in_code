{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andreidm92/Agents_in_code/blob/main/practice/Lesson_12_Nurse_Student_Quiz_Maker.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9e89b30",
      "metadata": {
        "id": "e9e89b30"
      },
      "source": [
        "\n",
        "# Day 12 — Nurse: Student Quiz Maker (по протоколам медсестры)\n",
        "\n",
        "## 🧠 Теория\n",
        "\n",
        "### LlamaIndex: RetrievalQA Chain\n",
        "\n",
        "**RetrievalQA** — это RAG-компонент, который:\n",
        "- Выполняет поиск фрагментов из медицинских протоколов и инструкций по уходу.\n",
        "- Генерирует ответы или тесты на основе найденных данных.\n",
        "\n",
        "```python\n",
        "from llama_index.core.query_engine import RetrievalQueryEngine\n",
        "\n",
        "query_engine = RetrievalQueryEngine.from_args(\n",
        "    retriever=retriever,\n",
        "    llm=llm\n",
        ")\n",
        "response = query_engine.query(\"Составь 5 вопросов по протоколу внутривенного вливания (IV)\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### LangGraph: Checkpointing\n",
        "\n",
        "Checkpointing позволяет:\n",
        "- сохранять прогресс агента при генерации тестов или обучающих сценариев;\n",
        "- восстанавливаться после ошибок или API-лимитов.\n",
        "\n",
        "```python\n",
        "graph = StateGraph(...)\n",
        "graph.persisted(\"redis://localhost:6379/0\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### LangGraph: StateGraph Basics\n",
        "\n",
        "Позволяет:\n",
        "- строить сложные пайплайны — генерация вопросов → проверка качества → сохранение;\n",
        "- включать циклы (например, если LLM сгенерировала слишком простой вопрос — повторить).\n",
        "\n",
        "```python\n",
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "builder = StateGraph()\n",
        "builder.add_node(\"generate_quiz\", generate_quiz)\n",
        "builder.set_entry_point(\"generate_quiz\")\n",
        "builder.add_edge(\"generate_quiz\", END)\n",
        "\n",
        "graph = builder.compile()\n",
        "graph.invoke({})\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "7a82a32b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7a82a32b",
        "outputId": "100730b1-86a0-4bca-f83f-106b3280bcb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m720.4/720.4 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m273.8/273.8 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m81.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.8/295.8 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# ✅ Рекомендуемая установка\n",
        "!pip install -q -U llama-index==0.10.38 openai redis\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
        "from llama_index.core.node_parser import SentenceSplitter\n",
        "from llama_index.core.storage.storage_context import StorageContext\n",
        "from llama_index.core.vector_stores import SimpleVectorStore\n",
        "from llama_index.embeddings.openai import OpenAIEmbedding\n",
        "from llama_index.llms.openai import OpenAI\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFQ5SIvVDNxY",
        "outputId": "258d88ea-fe7f-4450-fd58-cdfdfe32c947"
      },
      "id": "dFQ5SIvVDNxY",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to\n",
            "[nltk_data]     /usr/local/lib/python3.11/dist-\n",
            "[nltk_data]     packages/llama_index/core/_static/nltk_cache...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, getpass\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Вставь OpenAI API ключ: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSlOGImyBCEh",
        "outputId": "96e2979c-1621-4fc0-ec3e-acde7d705ba3"
      },
      "id": "ZSlOGImyBCEh",
      "execution_count": 2,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Вставь OpenAI API ключ: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "06b9bf3a",
      "metadata": {
        "id": "06b9bf3a"
      },
      "outputs": [],
      "source": [
        "# 📚 Шаг 1: Загрузка и чтение лекций\n",
        "# TODO: Загрузите свои PDF-файлы в папку 'lectures'\n",
        "docs = SimpleDirectoryReader('lectures').load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "3fbf0439",
      "metadata": {
        "id": "3fbf0439"
      },
      "outputs": [],
      "source": [
        "# 🔍 Шаг 2: Индексация с эмбеддингами\n",
        "storage_context = StorageContext.from_defaults(vector_store=SimpleVectorStore())\n",
        "index = VectorStoreIndex.from_documents(\n",
        "    docs,\n",
        "    embed_model=OpenAIEmbedding(),\n",
        "    storage_context=storage_context\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "e0168f09",
      "metadata": {
        "id": "e0168f09"
      },
      "outputs": [],
      "source": [
        "# 🧠 Шаг 3: Построение QueryEngine\n",
        "llm = OpenAI(model=\"gpt-4\")\n",
        "query_engine = index.as_query_engine(llm=llm)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "d7de0fe9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7de0fe9",
        "outputId": "871b219f-5665-4aa8-d2e3-1e0e72918978"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Какую позу тела следует использовать для проявления интереса к тому, что говорит пациент?\n",
            "   а) Скрещенные руки и ноги\n",
            "   б) Наклон вперед\n",
            "   в) Отвернуться от пациента\n",
            "\n",
            "2. Какие жесты можно использовать для поощрения разговора с пациентом?\n",
            "   а) Кивание и улыбка\n",
            "   б) Махание руками\n",
            "   в) Пожатие плечами\n",
            "\n",
            "3. Какие вопросы обычно самые полезные в общении с пациентом?\n",
            "   а) Закрытые вопросы\n",
            "   б) Открытые вопросы\n",
            "   в) Риторические вопросы\n",
            "\n",
            "4. Что следует делать с словами пациента в разговоре?\n",
            "   а) Игнорировать их\n",
            "   б) Отражать их, повторяя в нескольких словах\n",
            "   в) Прерывать их\n",
            "\n",
            "5. Что следует избегать в общении с пациентом?\n",
            "   а) Частого употребления оценивающих слов\n",
            "   б) Использования простого языка\n",
            "   в) Поддержания контакта глазами\n",
            "\n",
            "6. Как следует реагировать на то, что думает и чувствует пациент?\n",
            "   а) Выражать согласие или несогласие\n",
            "   б) Реагировать спокойно, не выражая согласия или несогласия\n",
            "   в) Игнорировать его мысли и чувства\n",
            "\n",
            "7. Что следует делать, если пациенту неудобно лежать?\n",
            "   а) Рассказать о профилактике пролежней\n",
            "   б) Помочь ему занять другое положение в постели\n",
            "   в) Оставить его в прежнем положении\n",
            "\n",
            "8. Какой язык следует использовать при общении с пациентом?\n",
            "   а) Профессиональный медицинский язык\n",
            "   б) Простой и доступный язык\n",
            "   в) Сложный и научный язык\n"
          ]
        }
      ],
      "source": [
        "# ❓ Шаг 4: Пример генерации quiz\n",
        "response = query_engine.query(\n",
        "    'Составь quiz по общению в сестринском деле на русском языке '\n",
        ")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "📌 Что делает graph.persisted(...)?\n",
        "Когда ты вызываешь:\n",
        "\n",
        "graph.persisted(\"redis://localhost:6379/0\")\n",
        "это говорит LangGraph:\n",
        "\n",
        "* «Сохраняй всё состояние агента (включая переменные, шаги и промежуточные данные) в Redis».\n",
        "\n",
        "При падении сервиса или повторном запуске — агент продолжит с того же места.\n",
        "\n",
        "🏥 Почему это актуально в твоём проекте Nurse: Quiz Maker?\n",
        "Если ты хочешь:\n",
        "\n",
        "- генерировать длинные тесты\n",
        "\n",
        "- обрабатывать несколько лекций\n",
        "\n",
        "- или делать это через потоковое взаимодействие\n",
        "\n",
        "…то Redis-чекпоинтинг поможет:\n",
        "\n",
        "- избежать потерь при сбоях,\n",
        "\n",
        "- разделить генерацию на несколько шагов,\n",
        "\n",
        "- и вообще вести себя как серьёзный обучающий ассистент.\n",
        "\n",
        "💡 Пример практического использования:"
      ],
      "metadata": {
        "id": "GsU7M06nBQRQ"
      },
      "id": "GsU7M06nBQRQ"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langgraph\n",
        "!pip install -q langgraph-checkpoint-redis redis"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29DY7lMkCWtQ",
        "outputId": "6b7cce8e-6a13-431d-d39e-3488fe3e4652"
      },
      "id": "29DY7lMkCWtQ",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/58.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/272.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m272.8/272.8 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/129.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.7/129.7 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import StateGraph, END\n",
        "from langgraph.checkpoint.redis import RedisSaver\n",
        "from typing import TypedDict\n",
        "\n",
        "class QuizState(TypedDict):\n",
        "    topic: str\n",
        "    query_engine: any\n",
        "    quiz: str\n",
        "    done: bool\n",
        "\n",
        "def generate_quiz_node(state: dict) -> dict:\n",
        "    topic = state.get(\"topic\", \"общение в сестринском деле\")\n",
        "    prompt = f\"Сгенерируй 3 вопроса по теме '{topic}' с вариантами ответов\"\n",
        "    response = state[\"query_engine\"].query(prompt)\n",
        "    return {\"quiz\": str(response), \"done\": True}\n",
        "\n",
        "graph = StateGraph(state_schema=QuizState)\n",
        "graph.add_node(\"generate\", generate_quiz_node)\n",
        "graph.set_entry_point(\"generate\")\n",
        "graph.add_edge(\"generate\", END)\n",
        "\n",
        "# ✅ Используем контекстный менеджер\n",
        "\n",
        "compiled = graph.compile()\n",
        "compiled.invoke({\n",
        "    \"query_engine\": query_engine,\n",
        "    \"topic\": \"общение в сестринском деле\"\n",
        "})\n",
        "\n",
        "# with RedisSaver.from_conn_string(\"redis://localhost:6379\") as checkpointer:\n",
        "#     compiled = graph.compile(checkpointer=checkpointer)\n",
        "#     compiled.invoke({\n",
        "#         \"query_engine\": query_engine,\n",
        "#         \"topic\": \"общение в сестринском деле\"\n",
        "#     })\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BgIsKWbLCBxE",
        "outputId": "b9bf5a41-bd04-4dbc-d6f7-e9f103de86cd"
      },
      "id": "BgIsKWbLCBxE",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'topic': 'общение в сестринском деле',\n",
              " 'query_engine': <llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine at 0x7ae2c4ac6050>,\n",
              " 'quiz': '1. Какая поза тела рекомендуется при общении с пациентом в сестринском деле?\\n   a) Скрещенные руки и ноги\\n   b) Открытая поза, носки ног направлены к пациенту\\n   c) Поза с отвернутым от пациента телом\\n   d) Поза с закрытыми глазами\\n\\n2. Какие вопросы считаются наиболее полезными при общении с пациентом?\\n   a) Закрытые вопросы, на которые можно ответить \"да\" или \"нет\"\\n   b) Вопросы, начинающиеся с оценивающих слов\\n   c) Открытые вопросы, начинающиеся с вопросительных слов\\n   d) Вопросы, требующие только односложного ответа\\n\\n3. Как следует реагировать на мысли и чувства пациента в сестринском деле?\\n   a) Выражать согласие или несогласие\\n   b) Реагировать спокойно, не выражая согласия или несогласия\\n   c) Игнорировать их\\n   d) Критиковать их',\n",
              " 'done': True}"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**StateGraph — основная структура LangGraph, граф состояний.**\n",
        "\n",
        "\n",
        "END — специальная метка для финального узла.\n",
        "\n",
        "RedisSaver — механизм сохранения состояния в Redis (не используется в Colab, но пригодится в продакшене).\n",
        "\n",
        "TypedDict — типизация для состояния графа.\n",
        "\n",
        "📋 Определение состояния:\n",
        "\n",
        "class QuizState(TypedDict):\n",
        "    topic: str\n",
        "    query_engine: any\n",
        "    quiz: str\n",
        "    done: bool\n",
        "\n",
        "Ты явно описал, какие поля присутствуют в состоянии агента (state) на каждом шаге:\n",
        "\n",
        "тема теста,\n",
        "\n",
        "объект query_engine,\n",
        "\n",
        "сгенерированный текст quiz,\n",
        "\n",
        "флаг готовности done.\n",
        "\n",
        "\n",
        "🧠 Узел графа:\n",
        "\n",
        "\n",
        "def generate_quiz_node(state: dict) -> dict:\n",
        "    topic = state.get(\"topic\", \"общение в сестринском деле\")\n",
        "    prompt = f\"Сгенерируй 3 вопроса по теме '{topic}' с вариантами ответов\"\n",
        "    response = state[\"query_engine\"].query(prompt)\n",
        "    return {\"quiz\": str(response), \"done\": True}\n",
        "\n",
        "Функция-узел, которая:\n",
        "\n",
        "Берёт тему из state\n",
        "\n",
        "Генерирует промпт\n",
        "\n",
        "Запускает query_engine.query(...)\n",
        "\n",
        "Возвращает результат в quiz и помечает, что задача выполнена (done: True)\n",
        "\n",
        "🔁 Построение графа:\n",
        "\n",
        "\n",
        "graph = StateGraph(state_schema=QuizState)\n",
        "graph.add_node(\"generate\", generate_quiz_node)\n",
        "graph.set_entry_point(\"generate\")\n",
        "graph.add_edge(\"generate\", END)\n",
        "\n",
        "\n",
        "Задаётся граф с состоянием QuizState.\n",
        "\n",
        "Добавляется один узел \"generate\".\n",
        "\n",
        "Он — точка входа (set_entry_point).\n",
        "\n",
        "После выполнения — переход в END.\n",
        "\n",
        "\n",
        "🏁 Выполнение:\n",
        "\n",
        "\n",
        "compiled = graph.compile()\n",
        "compiled.invoke({\n",
        "    \"query_engine\": query_engine,\n",
        "    \"topic\": \"общение в сестринском деле\"\n",
        "})\n",
        "\n",
        "compile() превращает описание графа в исполняемый агент.\n",
        "\n",
        "invoke(...) запускает его, передавая начальное состояние.\n",
        "\n",
        "💾 (опционально) Чекпоинтинг:\n",
        "\n",
        "with RedisSaver.from_conn_string(...) as checkpointer:\n",
        "    compiled = graph.compile(checkpointer=checkpointer)\n",
        "\n",
        "Если ты хочешь сохранять состояние (например, на сервере), ты бы подключил RedisSaver.\n",
        "\n",
        "📌 Если хочешь Redis:\n",
        "Зарегистрируйся на Redis Cloud → создай бесплатный Redis инстанс → получишь URL вроде redis://<username>:<password>@<host>:<port>.\n",
        "\n",
        "Вставь его вместо localhost:6379.\n",
        "\n",
        "🔁 Этот паттерн — отличная заготовка для более сложных агентов: можно добавлять шаги (генерация, валидация, экспорт), циклы, обработку ошибок и мн.др."
      ],
      "metadata": {
        "id": "isX6ip-lKy8c"
      },
      "id": "isX6ip-lKy8c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "782ad706",
      "metadata": {
        "id": "782ad706"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}